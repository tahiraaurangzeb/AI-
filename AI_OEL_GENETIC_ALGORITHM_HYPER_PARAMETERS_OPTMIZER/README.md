# Genetic Algorithm Implementation

**A Python implementation of a Genetic Algorithm (GA)**  
This program demonstrates the working of a genetic algorithm, including:
- Population initialization
- Fitness evaluation
- Selection
- Crossover
- Mutation

---

**Problem Statement**  
Training a neural network to achieve optimal performance in terms of accuracy and loss on a given dataset requires careful selection of hyperparameters, such as the number of neurons in hidden layers and the learning rate. These hyperparameters significantly impact the model's ability to generalize and perform well on unseen data. However, manually tuning hyperparameters is time-consuming and often leads to suboptimal results due to the sheer size of the search space.

The objective of this project is to automate the process of hyperparameter optimization for a multi-layer artificial neural network (ANN) used for image classification. Specifically, we aim to optimize the following parameters for an ANN with two hidden layers:
1. Number of neurons in the first hidden layer.  
2. Number of neurons in the second hidden layer.  
3. Learning rate for the optimizer.  

The dataset used for this problem is the MNIST dataset, which contains grayscale images of handwritten digits (28x28 pixels) with 10 classes (digits 0-9).

---

**Proposed Solution**  
We propose the use of Genetic Algorithms (GA) to efficiently search for the optimal hyperparameters. Genetic Algorithms are inspired by the process of natural selection and are effective in solving optimization problems with large and complex search spaces.

---

**Contributors**  
- **Manahil Ejaz** (CS-22011)  
- **Neha Nauman Khan** (CS-22024)  
- **Tahira Aurangzeb** (CS-21052)